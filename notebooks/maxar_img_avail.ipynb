{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maxar Image Availability Analysis\n",
    "\n",
    "The Maxar image availability workflow takes as input a list of TerraFund project ids and returns as output a csv listing every project and how much of that projectâ€™s area has Maxar imagery coverage.\n",
    "\n",
    "#### Workflow:\n",
    "1. Pull info on project characteristics for the entire portfolio using the TerraMatch API\n",
    "    - Repo/notebook: terrafund-portfolio-analysis/tm-api.ipynb\n",
    "    - Input: list of TerraFund project IDs\n",
    "    - Output: csv of all project features\n",
    "2. Using the TM API csv, pull Maxar metadata\n",
    "    - Repo/notebook: maxar-tools/decision-tree-metadata.ipynb and maxar-tools/src/decision_tree.py (? may need to change b/c of my additions to the acquire_metadata function)\n",
    "    - Input: csv of project features\n",
    "    - Output: csv of maxar metadata\n",
    "3. Calculate the percent area of each project with available Maxar imagery\n",
    "    - Repo/notebook: terrafund-portfolio-analysis/maxar-img-avail.ipynb and terrafund-portfolio-analysis/src/image_coverage.py\n",
    "    - Input: csv of maxar metadata and csv of TM project features\n",
    "    - Output: csv of project features and percent imagery coverage, csv of percent imagery coverage aggregated to project level, csv of polygons with low imagery coverage\n",
    "4. Identify projects with highest imagery coverage to use for the RS image availability simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import image_coverage as img_cover\n",
    "import analyze_img_coverage as analyze\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming convention\n",
    "run_name = 'cohort1'\n",
    "run_file = 'tf_cohort1'\n",
    "\n",
    "# File paths\n",
    "feats = f'../data/{run_file}/tm_api_{run_name}_2025-04-01.csv' # CSV of polygon metadata & geometries from TM API (infile)\n",
    "maxar_md = f'../data/{run_file}/imagery_availability/comb_img_availability_{run_name}_2025-04-01.csv' # CSV of metadata for Maxar images corresponding to polygons (infile)\n",
    "results_path = f'../data/{run_file}/results/baseline/' # File path to save results to\n",
    "\n",
    "# Define filtering thesholds (stored in a dictionary)\n",
    "filters = {\n",
    "    'cloud_cover': 50,          # Remove images with >50% cloud cover\n",
    "    'off_nadir': 30,            # Remove images with >30Â° off-nadir angle\n",
    "    'sun_elevation': 30,        # Keep only images where sun elevation >30Â°\n",
    "    'date_range': (-366, 0),    # Date range of 1 year before plantstart\n",
    "    'img_count': 1,             # Threshold for identifying image availability (REASSESS)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Image Availability by Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing polygon data...\n",
      "There are 0 polygons with invalid geometries.\n",
      "All invalid geometries were fixed successfully.\n",
      "There are 7 unique polygons for 2 projects in this dataset.\n",
      "Processing Maxar image data...\n",
      "There are 137 images for 7 polygons in 2 projects in this dataset.\n",
      "Merging polygon metadata into image data...\n",
      "Total images in img_gdf: 137\n",
      "Total polygons in poly_gdf: 7\n",
      "Total rows in merged dataset: 137\n",
      "Unique polygons in merged dataset: 7\n",
      "There 0 polygons without images in the merged dataset\n",
      "Polygons without images (dropped at this stage): []\n",
      "Total images before filtering: 137\n",
      "Total images after filtering: 28\n",
      "Polygons with at least one valid image: 7\n",
      "Computing coverage for polygon 0cf9fc3e-43d5-424d-a998-f66cc34e86b0\n",
      "Computing coverage for polygon 02faceea-68cb-47c5-b25a-e39771c9e8d9\n",
      "Logging low coverage for polygon 02faceea-68cb-47c5-b25a-e39771c9e8d9: 7.210444509070234%\n",
      "Computing coverage for polygon fdfc1a6b-3ab3-4642-b91b-9584d4207cf8\n",
      "Computing coverage for polygon 2210ca48-6683-4c8b-8967-bf4647c4651b\n",
      "Computing coverage for polygon 31ab5498-d4c9-4f78-9f88-c242daf97aa8\n",
      "Computing coverage for polygon 8e82add8-8a9b-4af2-bc74-e2e69297c9d3\n",
      "Computing coverage for polygon 60d22994-254c-4581-a761-88f55c9d3447\n",
      "There are 2 projects being analyzed.\n",
      "Logging low image coverage polygons to ../data/tf_cohort1/results/baseline/.\n",
      "Imagery coverage results saved to ../data/tf_cohort1/results/baseline/\n"
     ]
    }
   ],
   "source": [
    "### 1. LOAD POLYGON AND IMAGE DATA ###\n",
    "poly_df = pd.read_csv(feats)\n",
    "img_df = pd.read_csv(maxar_md)\n",
    "\n",
    "### 2. PREPROCESS POLYGON AND IMAGE DATA ###\n",
    "poly_gdf = img_cover.preprocess_polygons(poly_df, debug=True)\n",
    "img_gdf = img_cover.preprocess_images(img_df, debug=True)\n",
    "\n",
    "### 3. MERGE POLYGON METADATA INTO IMAGE DATA ###\n",
    "merged_gdf, missing_polygons_list = img_cover.merge_polygons_images(img_gdf, poly_gdf, debug=True)\n",
    "\n",
    "### 4. FILTER IMAGES ###\n",
    "img_gdf_filtered = img_cover.filter_images(merged_gdf, filters, debug=True)\n",
    "\n",
    "### 5. COMPUTE POLYGON-LEVEL IMAGERY COVERAGE ###\n",
    "# Initialize storage for results & low-coverage polygons list\n",
    "low_img_coverage_log = []\n",
    "results = []\n",
    "\n",
    "# Iterate through all polygons and compute imagery coverage per polygon\n",
    "for poly_id, project_id in zip(poly_gdf['poly_id'], poly_gdf['project_id']):\n",
    "    result = img_cover.compute_polygon_image_coverage(poly_id, project_id, poly_gdf, img_gdf_filtered, low_img_coverage_log)\n",
    "    results.append(result)\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['poly_id', 'project_id', 'best_image', 'num_images',\n",
    "                                            'poly_area_ha', 'overlap_area_ha', 'percent_img_cover'])\n",
    "results_df['best_image'] = results_df['best_image'].fillna(\"None\")\n",
    "\n",
    "# Convert low-coverage log to DataFrame\n",
    "#low_coverage_polygons_df = pd.DataFrame(low_img_coverage_log)\n",
    "\n",
    "### 6. AGGREGATE TO PROJECT-LEVEL COVERAGE ###\n",
    "project_results_df = img_cover.aggregate_project_image_coverage(results_df, debug=True)\n",
    "\n",
    "### 7. SAVE RESULTS ###\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Percent imagery coverage by polygon\n",
    "results_df.to_csv(f\"{results_path}polygon_imagery_coverage_{run_name}_{today}.csv\", index=False)\n",
    "\n",
    "# Percent imagery coverage by project\n",
    "project_results_df.to_csv(f\"{results_path}project_imagery_coverage_{run_name}_{today}.csv\", index=False)\n",
    "\n",
    "# Polygons with low imagery coverage\n",
    "if low_img_coverage_log:\n",
    "    low_coverage_polygons_df = pd.DataFrame(low_img_coverage_log)\n",
    "    print(f\"Logging low image coverage polygons to {results_path}.\")\n",
    "    low_coverage_polygons_df['best_image'] = low_coverage_polygons_df['best_image'].fillna(\"None\")\n",
    "    low_coverage_polygons_df.to_csv(f\"{results_path}low_coverage_polygons_{run_name}_{today}.csv\", index=False)\n",
    "\n",
    "print(f\"Imagery coverage results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Maxar Image Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Read in files\n",
    "# Image availability by project\n",
    "project_img_avail = pd.read_csv(f\"{results_path}project_imagery_coverage_{run_name}_{today}.csv\")\n",
    "\n",
    "# Low coverage polygons\n",
    "low_coverage_poly = pd.read_csv(f\"{results_path}low_coverage_polygons_{run_name}_{today}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Projects with â‰¥ 90% image coverage: 2\n",
      "ðŸ†” Project IDs:\n",
      " - 449adf55-f6f8-4f17-97d3-ab6f6bf6676d\n",
      " - cf106374-3dd4-401d-80ba-25b70247381a\n"
     ]
    }
   ],
   "source": [
    "# High image availability projects\n",
    "analyze.count_projs_wi_img_avail(project_img_avail, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
