{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maxar Image Availability Analysis\n",
    "\n",
    "The Maxar image availability workflow takes as input a list of TerraFund project ids and returns as output a csv listing every project and how much of that project’s area has Maxar imagery coverage.\n",
    "\n",
    "#### Workflow:\n",
    "1. Pull info on project characteristics for the entire portfolio using the TerraMatch API\n",
    "    - Repo/notebook: terrafund-portfolio-analysis/tm-api.ipynb\n",
    "    - Input: list of TerraFund project IDs\n",
    "    - Output: csv of all project features\n",
    "2. Using the TM API csv, pull Maxar metadata\n",
    "    - Repo/notebook: maxar-tools/decision-tree-metadata.ipynb and maxar-tools/src/decision_tree.py (? may need to change b/c of my additions to the acquire_metadata function)\n",
    "    - Input: csv of project features\n",
    "    - Output: csv of maxar metadata\n",
    "3. Create imagery features (??)\n",
    "    - Repo/notebook: terrafund-portfolio-analysis/maxar-img-avail.py\n",
    "    - Input: csv of maxar metadata and csv of TM project features\n",
    "    - Output: csv of project features and percent imagery coverage\n",
    "4. Identify projects with 100% imagery coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # keep\n",
    "import geopandas as gpd # keep\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape # keep\n",
    "from shapely.geometry import Polygon, Point # keep ?\n",
    "from shapely import union_all \n",
    "import ast # keep\n",
    "from datetime import datetime, timedelta # keep datetime\n",
    "import re\n",
    "import os\n",
    "import math \n",
    "import requests\n",
    "import yaml # keep\n",
    "import json\n",
    "import pyproj\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import image_availability as img \n",
    "import process_api_results as clean\n",
    "import decision_trees as tree\n",
    "import tm_api_utils as api_request\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "tm_auth_path = '../secrets.yaml'\n",
    "tm_staging_url = \"https://api-staging.terramatch.org/research/v3/sitePolygons?\"                 # use for testing queries\n",
    "tm_prod_url = \"https://api.terramatch.org/research/v3/sitePolygons?\"                            # Use to pull data for analysis'\n",
    "approved_projects = '../terrafund-portfolio-analyses/projects_all_approved_202501091214.csv'    # List of projects with approved polygons\n",
    "feats = '../data/tm_api_TEST.csv'                                                               # Polygon metadata & geometries from TM API\n",
    "maxar_feats = '/home/darby/github_repos/maxar-tools/data/tm_api_TEST.csv'                       # Polygon metadata & geometries from TM API saved to maxar-tools repo\n",
    "maxar_md = '../data/imagery_availability/comb_img_availability_2025-02-26.csv'                  # Metadata for Maxar images corresponding to polygons\n",
    "results_path = '../data/results/'                                                                               # File path to save results to\n",
    "\n",
    "# Define filtering thesholds (stored in a dictionary)\n",
    "filters = {\n",
    "    'cloud_cover': 50,          # Remove images with >50% cloud cover\n",
    "    'off_nadir': 30,            # Remove images with >30° off-nadir angle\n",
    "    'sun_elevation': 30,        # Keep only images where sun elevation >30°\n",
    "    'date_range': (-366, 0),    # Date range of 1 year before plantstart\n",
    "    'img_count': 1,             # Threshold for identifying image availability (REASSESS)\n",
    "    'ev_range': (730,1095)      # Early verification window (2-3 years after plantstart date) (REASSESS)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Workflow Outline (DON'T RUN!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: LOAD AND PREPROCESS DATA\n",
    "# 1.1: Load polygon dataset\n",
    "poly_csv = gpd.GeoDataFrame(polygon geometries & metadata)\n",
    "\n",
    "# 1.2 Load image dataset\n",
    "img_csv = gpd.GeoDataFrame(maxar image geometries & metadata)\n",
    "\n",
    "# 1.3 Preprocess the data\n",
    "poly_gdf = preprocess_polygons(poly_csv) # Clean data, convert geometries, enforce CRS\n",
    "img_gdf = preprocess_images(img_csv) # Clean data, convert geometries, enforce CRS\n",
    "\n",
    "\n",
    "# Step 2: MERGE POLYGON DATA WITH IMAGE DATA\n",
    "merged_gdf = img_gdf.merge(poly_gdf, on=['project_id', 'poly_id'], how='left')\n",
    "\n",
    "# Step 3: PRE-FILTER IMAGES\n",
    "filtered_images = merged_gdf where:\n",
    "    (date is within allowed date range) &\n",
    "    (cloud cover < cloud_thresh) &\n",
    "    (off-nadir angle < off_nadir_thresh) &\n",
    "    (sun elevation < sun_elev_thresh)\n",
    "\n",
    "# Step 4: ITERATE THROUGH PROJECTS AND POLYGONS TO CALCULATE IMAGERY COVERAGE\n",
    "# 4.1 Create a dictionary for project-polygon mapping\n",
    "project_polygons = {project_id: list of poly_ids associated with that project} # Create a dictionary\n",
    "\n",
    "# 4.2 Initialize list to store low coverage cases\n",
    "low_img_coverage_log = []\n",
    "\n",
    "# 4.3 Iterate through each project\n",
    "for each project_id in project_polygons:\n",
    "\n",
    "    # 4.4 Get all polygons for this project\n",
    "    project_polygons_list = list of poly_ids for this project_id\n",
    "\n",
    "    # 4.5 Iterate through each polygon in the project\n",
    "    for each poly_id in project_polygons_list:\n",
    "    \n",
    "        # 4.6 Get all images associated with this polygon\n",
    "        poly_images = filtered_images[filtered_images['poly_id'] == poly_id]\n",
    "\n",
    "        # Count the number of available images\n",
    "        num_images = len(poly_images)\n",
    "\n",
    "        # If no valid image exists, record 0% coverage\n",
    "        if poly_images is empty:\n",
    "            store result: (poly_id, project_id, None, num_images, 0, 0) # No images available\n",
    "            continue\n",
    "\n",
    "        # 4.7 Select the best image (lowest cloud cover)\n",
    "        best_image = select_best_image(poly_images)\n",
    "\n",
    "        # 4.8 Get polygon and image geometries\n",
    "        poly_geom = poly_gdf[poly_gdf['poly_id'] == poly_id].geometry.iloc[0]\n",
    "        best_img_geom = best_image['img_geom']\n",
    "\n",
    "        # 4.9 Compute UTM Zone and reproject geometries\n",
    "        poly_centroid = compute centroid of poly_geom\n",
    "        utm_crs = get UTM CRS from centroid\n",
    "        poly_geom_reprojected = reproject poly_geom to utm_crs\n",
    "        best_img_geom_reprojected = reproject best_img_geom to utm_crs\n",
    "\n",
    "        # 4.10 Calculate the polygon area dynamically (in hectares)\n",
    "        poly_area_ha = poly_geom_reprojected.area / 10000\n",
    "\n",
    "        # 4.11 Calculate area of overlap\n",
    "        overlap_area = poly_geom_reprojected union best_img_geom_reprojected\n",
    "        overlap_area_ha = overlap_area / 10000\n",
    "\n",
    "        # 4.12 Compute percent of polygon area covered\n",
    "        percent_img_cover = (overlap_area / poly_area_ha) * 100\n",
    "\n",
    "        # 4.13 Log cases where imagery coverage is unexpectedly low\n",
    "        if percent_img_cover < 50:\n",
    "            log_entry = {\n",
    "                'poly_id': poly_id,\n",
    "                'project_id': project_id,\n",
    "                'best_image': best_image['title'],\n",
    "                'num_images': num_images,\n",
    "                'poly_area_ha': poly_area_ha,\n",
    "                'overlap_area_ha': overlap_area_ha,\n",
    "                'percent_img_cover': percent_img_cover\n",
    "            }\n",
    "            low_img_coverage_log.append(log_entry)\n",
    "\n",
    "        # 4.14 Store results\n",
    "        store result: (poly_id, project_id, best_image['title'], num_images, poly_area_ha, overlap_area_ha, percent_img_cover)\n",
    "\n",
    "# STEP 5: EXPORT LOW COVERAGE LOG IF NEEDED\n",
    "if low_img_coverage_log is not empty:\n",
    "    export_to_csv(low_img_coverage_log, \"low_coverage_polygons.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: LOAD & PREPROCESS DATA\n",
    "Goal: ensure input data is clean & structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.1 LOAD IN POLYGON AND IMAGE CSVS\n",
    "poly_df = pd.read_csv(feats)\n",
    "img_df = pd.read_csv(maxar_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.2 PREPROCESS POLYGON DATA\n",
    "def preprocess_polygons(poly_df, debug=False):\n",
    "    \"\"\"\n",
    "    Cleans up a dataframe of polygon metadata & geometries from the TerraMatch API and \n",
    "    converts it into a GeoDataframe\n",
    "\n",
    "    Args:\n",
    "        poly_df (DataFrame): Raw polygon dataset.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: Processed polygon dataset with a geometry column as a shapely object.\n",
    "    \"\"\"\n",
    "    # Enforce lowercase column names\n",
    "    poly_df.columns = poly_df.columns.str.lower()\n",
    "\n",
    "    # Rename 'name' and 'geometry' columns\n",
    "    poly_df = poly_df.rename(columns={'name': 'poly_name', 'geometry': 'poly_geom'})\n",
    "\n",
    "    # Convert 'plantstart' column to a datetime\n",
    "    poly_df['plantstart'] = pd.to_datetime(poly_df['plantstart'], errors='coerce')\n",
    "\n",
    "    # Convert stringified 'poly_geom' dictionaries into real dictionaries\n",
    "    poly_df['poly_geom'] = poly_df['poly_geom'].apply(lambda x: shape(ast.literal_eval(x)) if isinstance(x, str) else shape(x))\n",
    "\n",
    "    # Convert 'poly_geom' dictionaries from WKT to Shapely objects\n",
    "    poly_df['poly_geom'] = poly_df['poly_geom'].apply(shape)\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "    poly_gdf = gpd.GeoDataFrame(poly_df, geometry='poly_geom', crs=\"EPSG:4326\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"There are {len(poly_gdf.poly_id.unique())} unique polygons for {len(poly_gdf.project_id.unique())} projects in this dataset.\")\n",
    "\n",
    "    return poly_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.3 PREPROCESS MAXAR IMAGERY DATA\n",
    "def preprocess_images(img_df, debug=True):\n",
    "    \"\"\"\n",
    "    Cleans up a dataframe of maxar image metadata & geometries from the Maxar Discovery API and \n",
    "    converts it into a GeoDataframe\n",
    "\n",
    "    Args:\n",
    "        img_df (DataFrame): Raw image metadata dataset.\n",
    "    \n",
    "    Returns: \n",
    "        GeoDataFrame: Processed image dataset with a geometry column as a shapely object.\n",
    "    \"\"\"\n",
    "    # Convert 'datetime' column to a datetime and rename\n",
    "    img_df.loc[:, 'datetime'] = pd.to_datetime(img_df['datetime'], format='%Y-%m-%dT%H:%M:%S.%fZ', errors='coerce') # Convert to datetime type\n",
    "    img_df.loc[:, 'datetime'] = img_df['datetime'].apply(lambda x: x.replace(tzinfo=None) if pd.notna(x) else x)    # Remove time zone info\n",
    "    \n",
    "    # Rename the 'datetime' column to 'img_date'\n",
    "    img_df = img_df.rename(columns={'datetime': 'img_date'}) # Rename the column img_date\n",
    "\n",
    "    # Select the relevent columns from img_df\n",
    "    img_df = img_df[['title', 'project_id', 'poly_id', 'img_date', 'area:cloud_cover_percentage', 'eo:cloud_cover', 'area:avg_off_nadir_angle', 'view:sun_elevation', 'img_geom']]\n",
    "\n",
    "    # Convert stringified 'poly_geom' dictionaries into real dictionaries\n",
    "    img_df['img_geom'] = img_df['img_geom'].apply(lambda x: shape(ast.literal_eval(x)) if isinstance(x, str) else shape(x))\n",
    "\n",
    "    # Convert 'img_geom' (image footprint geometries) from WKT to Shapely objects\n",
    "    img_df['img_geom'] = img_df['img_geom'].apply(shape)\n",
    "\n",
    "    # Convert DataFrame to GeoDataFrame\n",
    "    img_gdf = gpd.GeoDataFrame(img_df, geometry='img_geom', crs=\"EPSG:4326\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"There are {len(img_gdf)} images for {len(img_gdf.poly_id.unique())} polygons in {len(img_gdf.project_id.unique())} projects in this dataset.\")\n",
    "\n",
    "    return img_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: MERGE & FILTER DATA\n",
    "Goal: link images to polygons and apply filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.1 MERGE THE POLYGON ATTRIBUTES TO THE IMAGES GEODATAFRAME\n",
    "def merge_polygons_images(img_gdf, poly_gdf, debug=True):\n",
    "    \"\"\" \n",
    "    Merges the polygon metadata into the Maxar image GeoDataFrame. All rows of the img_gdf are preserved.\n",
    "    Also records polygons that are dropped because they don't have any associated images.\n",
    "\n",
    "    Args:\n",
    "        img_gdf (GeoDataFrame): Image metadata dataset (each row represents a Maxar image)\n",
    "        poly_gdf (GeoDataFrame): Polygon dataset (each row represents a polygon from the TM API)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (GeoDataFrame of merged dataset, list of missing polygons (poly_id, project_id))\n",
    "    \"\"\"\n",
    "    # Merge the image data with the polygon data (preserving image data rows and adding associated polygon attributes)\n",
    "    merged_gdf = img_gdf.merge(poly_gdf, on=['project_id', 'poly_id'], how='left')\n",
    "\n",
    "    # Identify polygons without any corresponding Maxar images\n",
    "    missing_polygons_df = poly_gdf[~poly_gdf['poly_id'].isin(merged_gdf['poly_id'])]\n",
    "\n",
    "    # Save poly_id and project_id of missing polygons as a list of tuples\n",
    "    missing_polygons_list = list(missing_polygons_df[['poly_id', 'project_id']].itertuples(index=False, name=None))\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Total images in img_gdf: {len(img_gdf)}\")\n",
    "        print(f\"Total polygons in poly_gdf: {len(poly_gdf)}\")\n",
    "        print(f\"Total rows in merged dataset: {len(merged_gdf)}\")\n",
    "        print(f\"Unique polygons in merged dataset: {len(merged_gdf['poly_id'].unique())}\")\n",
    "    \n",
    "        # Count polygons dropped due to no matching images\n",
    "        missing_polygons = len(poly_gdf[~poly_gdf['poly_id'].isin(merged_gdf['poly_id'])])\n",
    "        print(f\"There {missing_polygons} polygons without images in the merged dataset\")\n",
    "        print(f\"Polygons without images (dropped at this stage): {missing_polygons_list}\")\n",
    "\n",
    "    return merged_gdf, missing_polygons_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2 FILTER IMAGES BASED ON HARD CRITERIA\n",
    "def filter_images(merged_gdf, filters, debug=True):\n",
    "    \"\"\"\n",
    "    Filters the merged dataset to retain only images that meet filters for image quality.\n",
    "    The values for the filters can be changed in the parameters section.\n",
    "\n",
    "    Args:\n",
    "        merged_gdf (GeoDataFrame): Merged dataset of images and polygons.\n",
    "        filters (dict): Dictionary containing filter thresholds (in Parameters section of notebook)\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: Filtered dataset containing only the images that meet the criteria\n",
    "    \"\"\"\n",
    "    # Ensure date columns are in correct datetime format\n",
    "    merged_gdf['img_date'] = pd.to_datetime(merged_gdf['img_date'], errors='coerce')\n",
    "    merged_gdf['plantstart'] = pd.to_datetime(merged_gdf['plantstart'], errors='coerce')\n",
    "\n",
    "    # Compute the date difference (image capture date - plant start date)\n",
    "    merged_gdf['date_diff'] = (merged_gdf['img_date'] - merged_gdf['plantstart']).dt.days\n",
    "\n",
    "    # Apply filtering criteria to retain only images within the desired time range, cloud cover, \n",
    "    # off nadir angle, and sun elevation parameters\n",
    "    filtered_images = merged_gdf[\n",
    "        (merged_gdf['date_diff'] >= filters['date_range'][0]) &\n",
    "        (merged_gdf['date_diff'] <= filters['date_range'][1]) &\n",
    "        (merged_gdf['area:cloud_cover_percentage'] < filters['cloud_cover']) &\n",
    "        (merged_gdf['area:avg_off_nadir_angle'] <= filters['off_nadir']) &\n",
    "        (merged_gdf['view:sun_elevation'] >= filters['sun_elevation'])\n",
    "    ].copy()  # Copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Total images before filtering: {len(merged_gdf)}\")\n",
    "        print(f\"Total images after filtering: {len(filtered_images)}\")\n",
    "        print(f\"Polygons with at least one valid image: {filtered_images['poly_id'].nunique()}\")\n",
    "\n",
    "    return filtered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: PROCESS EACH POLYGON & COMPUTE IMAGERY COVERAGE\n",
    "Goal: Prepare polygons, select the best image, and calculate imagery coverage per polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1 GET THE BEST IMAGE FOR A GIVEN POLYGON\n",
    "def get_best_image(poly_images, debug=False):\n",
    "    \"\"\"\n",
    "    Selects the best image for a given polygon based on the lowest cloud cover. If multiple images have\n",
    "    the same cloud cover, selects the one closest to the plantstart date. \n",
    "\n",
    "    If we want to update this to include an \"expected coverage\" based on cloud cover and footprint overlap,\n",
    "    this is where it would go.\n",
    "\n",
    "    Args:\n",
    "        poly_images (GeoDataFrame): Subset of img_gdf_filtered containing images for one polygon.\n",
    "    \n",
    "    Returns:\n",
    "        GeoSeries: The best image row from poly_images\n",
    "    \"\"\"\n",
    "    # Create an absolute value date_diff column to help sort images by proximity to plantstart date\n",
    "    poly_images = poly_images.copy() # Avoid modifying the original dataframe\n",
    "    poly_images['abs_date_diff'] = poly_images['date_diff'].abs()\n",
    "\n",
    "    # Sort images by cloud cover (ascending) and then by date (closest to plantstart)\n",
    "    sorted_images = poly_images.sort_values(by=['area:cloud_cover_percentage', 'abs_date_diff'])\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n Debug: Sorted images for this polygon (using cloud cover, then proximity to plantstart date):\")\n",
    "        print(sorted_images[['title', 'area:cloud_cover_percentage', 'img_date', 'plantstart', 'abs_date_diff']])\n",
    "\n",
    "    # Select the best image (first row after sorting)\n",
    "    best_image = sorted_images.iloc[0]\n",
    "\n",
    "    return best_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.2 GET THE APPROPRIATE UTM CRS FOR A POLYGON BASED ON ITS CENTROID\n",
    "def get_utm_crs(longitude, latitude):\n",
    "    \"\"\"\n",
    "    Determines the appropriate UTM CRS for a given polygon based on the longitude and latitude\n",
    "    of its centroid.\n",
    "\n",
    "    Args:\n",
    "        longitude (float): Longitude of the polygon centroid.\n",
    "        latitude (float): Latitude of the polygon centroid.\n",
    "    \n",
    "    Returns:\n",
    "        str: EPSG code of the best UTM CRS.\n",
    "    \"\"\"\n",
    "\n",
    "    # UTM zones range from 0 to 60, each covering 6 degrees of longitude\n",
    "    utm_zone = int((longitude + 180) / 6) + 1\n",
    "\n",
    "    # EPSG code for UTM Northern vs. Southern hemisphere\n",
    "    epsg_code = 32600 + utm_zone if latitude >= 0 else 32700 + utm_zone\n",
    "\n",
    "    return f\"EPSG:{epsg_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.3 COMPUTE THE IMAGERY COVERAGE FOR A GIVEN POLYGON\n",
    "def compute_polygon_image_coverage(poly_id, project_id, poly_gdf, img_gdf_filtered,\n",
    "                                   low_img_coverage_log, min_coverage_threshold=50):\n",
    "    \"\"\"\n",
    "    Computes the percentage of a polygon's area that is covered by its best available Maxar image.\n",
    "\n",
    "    Args:\n",
    "        poly_id (str): Unique polygon ID\n",
    "        project_id (str): Unique project ID\n",
    "        poly_gdf (GeoDataFrame): Polygons dataset\n",
    "        img_gdf_filtered (GeoDataFrame): Images dataset filtered by hard criteria\n",
    "        low_img_coverage_log (list): List to store cases where imagery coverage is low\n",
    "        min_coverage_threshold (int): Imagery coverage threshold below which polygons are logged\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing (poly_id, project_id, best_image, num_images, poly_area_ha,\n",
    "        overlap_area_ha, percent_img_cover)\n",
    "    \"\"\"\n",
    "\n",
    "    ## Calculate the polygon's area from its geometry\n",
    "    # Explicitly retrieve the polygon row\n",
    "    polygon_row = poly_gdf.loc[poly_gdf['poly_id'] == poly_id]\n",
    "\n",
    "    # Retrieve the actual polygon geometry\n",
    "    poly_geom = polygon_row['poly_geom'].values[0]\n",
    "\n",
    "    # Compute UTM Zone based on polygon centroid and reproject polygon and image footprint\n",
    "    poly_centroid = poly_geom.centroid\n",
    "    utm_crs = get_utm_crs(poly_centroid.x, poly_centroid.y)\n",
    "\n",
    "    # Reproject the polygon geometry into a CRS with a unit of square meters\n",
    "    poly_reprojected = gpd.GeoDataFrame(polygon_row, geometry='poly_geom', crs=\"EPSG:4326\").to_crs(utm_crs)\n",
    "    poly_geom_reprojected = poly_reprojected.geometry.iloc[0] # Extract reprojected polygon\n",
    "\n",
    "    # Calculate polygon area dynamically (in hectares)\n",
    "    poly_area_ha = poly_geom_reprojected.area / 10_000\n",
    "\n",
    "    ## Get all images associated with this polygon\n",
    "    print(f\"Computing coverage for polygon {poly_id}\")\n",
    "    poly_images = img_gdf_filtered[img_gdf_filtered['poly_id'] == poly_id]\n",
    "    num_images = len(poly_images)\n",
    "\n",
    "    ## Handle polygons with no valid images\n",
    "    # If no valid images, log the case and return 0% imagery coverage\n",
    "    if poly_images.empty:\n",
    "        log_entry = {\n",
    "            'poly_id': poly_id,\n",
    "            'project_id': project_id,\n",
    "            'best_image': None,\n",
    "            'num_images': 0,\n",
    "            'poly_area_ha': poly_area_ha,\n",
    "            'overlap_area_ha': 0,\n",
    "            'percent_img_cover': 0,\n",
    "        }\n",
    "        print(f\"Logging low covarage for polygon {poly_id} because there is no available imagery\")\n",
    "        low_img_coverage_log.append(log_entry)\n",
    "\n",
    "        # Return after logging\n",
    "        return (poly_id, project_id, None, num_images, poly_area_ha, 0, 0)\n",
    "    \n",
    "    ## If there is at least one valid image\n",
    "    # Select the best image from the filtered images for the polygon\n",
    "    best_image = get_best_image(poly_images)\n",
    "\n",
    "    # Retrieve the geometry of the best image footprint\n",
    "    best_image_geom = best_image['img_geom']\n",
    "    \n",
    "    # Reproject the best image footprint's geometry\n",
    "    best_img_reprojected = gpd.GeoDataFrame([best_image], geometry=\"img_geom\", crs=\"EPSG:4326\").to_crs(utm_crs)\n",
    "    best_img_geom_reprojected = best_img_reprojected.geometry.iloc[0]\n",
    "\n",
    "    # Compute intersection between polygon geometry and best image's footprint geometry\n",
    "    overlap_area = poly_geom_reprojected.intersection(best_img_geom_reprojected).area\n",
    "    overlap_area_ha = overlap_area / 10_000\n",
    "\n",
    "    # Compute percentage of polygon covered by best image\n",
    "    percent_img_cover = (overlap_area_ha / poly_area_ha) * 100\n",
    "\n",
    "    # Log cases where the imagery coverage of the best image is below the threshold\n",
    "    if percent_img_cover < min_coverage_threshold or percent_img_cover == 0:\n",
    "        print(f\"Logging low coverage for polygon {poly_id}: {percent_img_cover}%\")\n",
    "        log_entry = {\n",
    "            'poly_id': poly_id,\n",
    "            'project_id': project_id,\n",
    "            'best_image': best_image['title'] if best_image is not None else None,\n",
    "            'num_images': num_images,\n",
    "            'poly_area_ha': poly_area_ha,\n",
    "            'overlap_area_ha': overlap_area_ha,\n",
    "            'percent_img_cover': percent_img_cover,\n",
    "        }\n",
    "        low_img_coverage_log.append(log_entry)\n",
    "\n",
    "    # Return results\n",
    "    return (poly_id, project_id, best_image['title'], num_images, poly_area_ha, overlap_area_ha,\n",
    "            percent_img_cover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: COMPUTE COVERAGE PER PROJECT\n",
    "Goal: aggregate the percent imagery cover per polygon to the project level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_project_image_coverage(results_df, debug=False):\n",
    "    \"\"\"\n",
    "    Aggregates the polygon-level image coverage data to the project level.\n",
    "\n",
    "    Args:\n",
    "        results_df (DataFrame): Contains polygon-level image coverage data.\n",
    "    \n",
    "    Returns:\n",
    "        project_coverage_df (DataFrame): Aggregated project-level imagery coverage summary\n",
    "    \"\"\"\n",
    "\n",
    "    # Group data by project_id\n",
    "    grouped = results_df.groupby('project_id')\n",
    "    if debug:\n",
    "        print(f\"There are {len(grouped.project_id.unique())} projects being analyzed.\")\n",
    "    \n",
    "    # Compute summary statistics per project\n",
    "    project_coverage_df = grouped.agg(\n",
    "        num_polygons=('poly_id', 'count'), # Total polygons\n",
    "        num_polygons_with_images=('percent_img_cover', lambda x: (x > 0).sum()), # Polygons with imagery\n",
    "        num_polygons_no_images=('percent_img_cover', lambda x: (x == 0).sum()), # Polygons with 0% imagery coverage\n",
    "        total_project_area_ha=('poly_area_ha', 'sum'), # Total area of the project in hectares (sum of polygon areas)\n",
    "        total_overlap_area_ha=('overlap_area_ha', 'sum'), # Total area of the project with imagery coverage (sum of per polygon area with imagery coverage)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Compute the total percent area of each project that has Maxar imagery coverage (final result)\n",
    "    project_coverage_df['total_percent_area_covered'] = (\n",
    "        (project_coverage_df['total_overlap_area_ha'] / project_coverage_df['total_project_area_ha']) * 100\n",
    "    )\n",
    "\n",
    "    return project_coverage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: EXPORT RESULTS\n",
    "Goal: save results for review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>siteid</th>\n",
       "      <th>geometry</th>\n",
       "      <th>plantstart</th>\n",
       "      <th>plantend</th>\n",
       "      <th>practice</th>\n",
       "      <th>targetsys</th>\n",
       "      <th>distr</th>\n",
       "      <th>numtrees</th>\n",
       "      <th>calcarea</th>\n",
       "      <th>indicators</th>\n",
       "      <th>establishmenttreespecies</th>\n",
       "      <th>reportingperiods</th>\n",
       "      <th>poly_id</th>\n",
       "      <th>project_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAVE KENYA WATER TOWERS, MOROB SUB-LOCATION SITE</td>\n",
       "      <td>approved</td>\n",
       "      <td>ae5a9efd-66b0-4985-8c4c-7e733fa9363e</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[35.58452...</td>\n",
       "      <td>5/1/2024</td>\n",
       "      <td>9/5/2024</td>\n",
       "      <td>tree-planting, assisted-natural-regeneration</td>\n",
       "      <td>agroforest</td>\n",
       "      <td>partial</td>\n",
       "      <td>45802.0</td>\n",
       "      <td>70.061969</td>\n",
       "      <td>[{'indicatorSlug': 'restorationByStrategy', 'y...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'dueAt': '2024-07-30T00:00:00.000Z', 'submit...</td>\n",
       "      <td>a91435c7-a179-4c1d-9891-de0fe1741654</td>\n",
       "      <td>146b6912-62a1-4b58-b027-466dc3295731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mwambani_2 (new)</td>\n",
       "      <td>approved</td>\n",
       "      <td>b38fcde9-e336-4fb0-b4ae-21fd6762c852</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[39.12436...</td>\n",
       "      <td>1/9/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tree-planting</td>\n",
       "      <td>mangrove</td>\n",
       "      <td>Null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.174912</td>\n",
       "      <td>[{'indicatorSlug': 'restorationByStrategy', 'y...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'dueAt': '2022-09-30T00:00:00.000Z', 'submit...</td>\n",
       "      <td>410696dc-9579-4412-9c7b-55194cb1867c</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mwambani_4 (new)</td>\n",
       "      <td>approved</td>\n",
       "      <td>b38fcde9-e336-4fb0-b4ae-21fd6762c852</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[39.12074...</td>\n",
       "      <td>1/9/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tree-planting</td>\n",
       "      <td>mangrove</td>\n",
       "      <td>Null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.189894</td>\n",
       "      <td>[{'indicatorSlug': 'restorationByStrategy', 'y...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'dueAt': '2022-09-30T00:00:00.000Z', 'submit...</td>\n",
       "      <td>f6871a61-a766-451a-be90-086219616cef</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mwambani_5 (new)</td>\n",
       "      <td>approved</td>\n",
       "      <td>b38fcde9-e336-4fb0-b4ae-21fd6762c852</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[39.11226...</td>\n",
       "      <td>1/9/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tree-planting</td>\n",
       "      <td>mangrove</td>\n",
       "      <td>Null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.102030</td>\n",
       "      <td>[{'indicatorSlug': 'restorationByStrategy', 'y...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'dueAt': '2022-09-30T00:00:00.000Z', 'submit...</td>\n",
       "      <td>9e745667-0701-434a-8ecb-d917fe2bcf29</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mwambani_6 (new)</td>\n",
       "      <td>approved</td>\n",
       "      <td>b38fcde9-e336-4fb0-b4ae-21fd6762c852</td>\n",
       "      <td>{'type': 'Polygon', 'coordinates': [[[39.10830...</td>\n",
       "      <td>1/9/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tree-planting</td>\n",
       "      <td>mangrove</td>\n",
       "      <td>Null</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.032552</td>\n",
       "      <td>[{'indicatorSlug': 'restorationByStrategy', 'y...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'dueAt': '2022-09-30T00:00:00.000Z', 'submit...</td>\n",
       "      <td>9e508b07-4534-4e04-bb5b-bb0d3734a796</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name    status  \\\n",
       "0  SAVE KENYA WATER TOWERS, MOROB SUB-LOCATION SITE  approved   \n",
       "1                                  Mwambani_2 (new)  approved   \n",
       "2                                  Mwambani_4 (new)  approved   \n",
       "3                                  Mwambani_5 (new)  approved   \n",
       "4                                  Mwambani_6 (new)  approved   \n",
       "\n",
       "                                 siteid  \\\n",
       "0  ae5a9efd-66b0-4985-8c4c-7e733fa9363e   \n",
       "1  b38fcde9-e336-4fb0-b4ae-21fd6762c852   \n",
       "2  b38fcde9-e336-4fb0-b4ae-21fd6762c852   \n",
       "3  b38fcde9-e336-4fb0-b4ae-21fd6762c852   \n",
       "4  b38fcde9-e336-4fb0-b4ae-21fd6762c852   \n",
       "\n",
       "                                            geometry plantstart  plantend  \\\n",
       "0  {'type': 'Polygon', 'coordinates': [[[35.58452...   5/1/2024  9/5/2024   \n",
       "1  {'type': 'Polygon', 'coordinates': [[[39.12436...   1/9/2022       NaN   \n",
       "2  {'type': 'Polygon', 'coordinates': [[[39.12074...   1/9/2022       NaN   \n",
       "3  {'type': 'Polygon', 'coordinates': [[[39.11226...   1/9/2022       NaN   \n",
       "4  {'type': 'Polygon', 'coordinates': [[[39.10830...   1/9/2022       NaN   \n",
       "\n",
       "                                       practice   targetsys    distr  \\\n",
       "0  tree-planting, assisted-natural-regeneration  agroforest  partial   \n",
       "1                                 tree-planting    mangrove     Null   \n",
       "2                                 tree-planting    mangrove     Null   \n",
       "3                                 tree-planting    mangrove     Null   \n",
       "4                                 tree-planting    mangrove     Null   \n",
       "\n",
       "   numtrees   calcarea                                         indicators  \\\n",
       "0   45802.0  70.061969  [{'indicatorSlug': 'restorationByStrategy', 'y...   \n",
       "1       NaN  11.174912  [{'indicatorSlug': 'restorationByStrategy', 'y...   \n",
       "2       NaN   2.189894  [{'indicatorSlug': 'restorationByStrategy', 'y...   \n",
       "3       NaN   5.102030  [{'indicatorSlug': 'restorationByStrategy', 'y...   \n",
       "4       NaN   5.032552  [{'indicatorSlug': 'restorationByStrategy', 'y...   \n",
       "\n",
       "  establishmenttreespecies                                   reportingperiods  \\\n",
       "0                       []  [{'dueAt': '2024-07-30T00:00:00.000Z', 'submit...   \n",
       "1                       []  [{'dueAt': '2022-09-30T00:00:00.000Z', 'submit...   \n",
       "2                       []  [{'dueAt': '2022-09-30T00:00:00.000Z', 'submit...   \n",
       "3                       []  [{'dueAt': '2022-09-30T00:00:00.000Z', 'submit...   \n",
       "4                       []  [{'dueAt': '2022-09-30T00:00:00.000Z', 'submit...   \n",
       "\n",
       "                                poly_id                            project_id  \n",
       "0  a91435c7-a179-4c1d-9891-de0fe1741654  146b6912-62a1-4b58-b027-466dc3295731  \n",
       "1  410696dc-9579-4412-9c7b-55194cb1867c  3a860077-df4c-4e95-8fec-41520c551243  \n",
       "2  f6871a61-a766-451a-be90-086219616cef  3a860077-df4c-4e95-8fec-41520c551243  \n",
       "3  9e745667-0701-434a-8ecb-d917fe2bcf29  3a860077-df4c-4e95-8fec-41520c551243  \n",
       "4  9e508b07-4534-4e04-bb5b-bb0d3734a796  3a860077-df4c-4e95-8fec-41520c551243  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1.1 LOAD IN POLYGON AND IMAGE CSVS\n",
    "poly_df = pd.read_csv(feats)\n",
    "img_df = pd.read_csv(maxar_md)\n",
    "\n",
    "poly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16 unique polygons for 3 projects in this dataset.\n"
     ]
    }
   ],
   "source": [
    "## 1.2 PREPROCESS POLYGON DATA\n",
    "poly_gdf = preprocess_polygons(poly_df, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 229 images for 16 polygons in 3 projects in this dataset.\n"
     ]
    }
   ],
   "source": [
    "## 1.2 PREPROCESS POLYGON DATA\n",
    "img_gdf = preprocess_images(img_df, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in img_gdf: 229\n",
      "Total polygons in poly_gdf: 16\n",
      "Total rows in merged dataset: 229\n",
      "Unique polygons in merged dataset: 16\n",
      "There 0 polygons without images in the merged dataset\n",
      "Polygons without images (dropped at this stage): []\n"
     ]
    }
   ],
   "source": [
    "## 2.1 MERGE THE POLYGON ATTRIBUTES TO THE IMAGES GEODATAFRAME\n",
    "merged_gdf, missing_polygons = merge_polygons_images(img_gdf, poly_gdf, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(missing_polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images before filtering: 229\n",
      "Total images after filtering: 30\n",
      "Polygons with at least one valid image: 15\n"
     ]
    }
   ],
   "source": [
    "### 3.1 FILTER IMAGES BASED ON HARD CRITERIA\n",
    "img_gdf_filtered = filter_images(merged_gdf, filters, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases: longitude, latitude → expected UTM zone and EPSG code\n",
    "test_coords = [\n",
    "    (-75, 40),   # Philadelphia, USA (Should be EPSG:32618)\n",
    "    (2.35, 48.85), # Paris, France (Should be EPSG:32631)\n",
    "    (120, -10),  # Indonesia (Southern Hemisphere, Should be EPSG:32751)\n",
    "    (-122, 37),  # San Francisco, USA (Should be EPSG:32610)\n",
    "    (35, 0),     # Near Equator (Should be EPSG:32636)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function on test coordinates\n",
    "for lon, lat in test_coords:\n",
    "    utm_crs = get_utm_crs(lon, lat)\n",
    "    print(f\"Longitude: {lon}, Latitude: {lat} → UTM CRS: {utm_crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing coverage for polygon a91435c7-a179-4c1d-9891-de0fe1741654\n",
      "Computing coverage for polygon 410696dc-9579-4412-9c7b-55194cb1867c\n",
      "Computing coverage for polygon f6871a61-a766-451a-be90-086219616cef\n",
      "Computing coverage for polygon 9e745667-0701-434a-8ecb-d917fe2bcf29\n",
      "Computing coverage for polygon 9e508b07-4534-4e04-bb5b-bb0d3734a796\n",
      "Computing coverage for polygon 1cbca6da-0024-47dc-bb3a-06f8727d1cd6\n",
      "Computing coverage for polygon e7223a4d-68c6-4d32-b140-f871dec62bd3\n",
      "Computing coverage for polygon 0b9ef620-327a-4be2-8b0c-50ec0fa06788\n",
      "Computing coverage for polygon e7e42658-360a-4452-8be4-60ea8d1ef0e7\n",
      "Computing coverage for polygon e18c2562-7f73-4fd2-a361-a6eee01ed71a\n",
      "Computing coverage for polygon 4d13b994-be20-4392-9f0f-68709607e96b\n",
      "Computing coverage for polygon c9b59851-e4b7-4271-ac99-f4e601f86e85\n",
      "Computing coverage for polygon 212d5966-2c94-4db7-98e9-4847cfdc4215\n",
      "Computing coverage for polygon 8bc43765-9e53-4702-ba97-13005b806126\n",
      "Computing coverage for polygon e41e8d8a-efa3-4626-bbfe-5af48f23b6da\n",
      "Computing coverage for polygon 0b35ba48-a92c-48da-83d8-c21ddcdc3c0f\n",
      "Logging low covarage for polygon 0b35ba48-a92c-48da-83d8-c21ddcdc3c0f because there is no available imagery\n",
      "Processed 16 polygons.\n",
      "1 polygons logged as low imagery coverage.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poly_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>best_image</th>\n",
       "      <th>num_images</th>\n",
       "      <th>poly_area_ha</th>\n",
       "      <th>overlap_area_ha</th>\n",
       "      <th>percent_img_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a91435c7-a179-4c1d-9891-de0fe1741654</td>\n",
       "      <td>146b6912-62a1-4b58-b027-466dc3295731</td>\n",
       "      <td>Maxar WV02 Image 10300100E93C2A00</td>\n",
       "      <td>1</td>\n",
       "      <td>69.680122</td>\n",
       "      <td>44.213046</td>\n",
       "      <td>63.451447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410696dc-9579-4412-9c7b-55194cb1867c</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV03 Image 1040010068D32900</td>\n",
       "      <td>2</td>\n",
       "      <td>11.092460</td>\n",
       "      <td>11.092460</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f6871a61-a766-451a-be90-086219616cef</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV03 Image 1040010068D32900</td>\n",
       "      <td>2</td>\n",
       "      <td>2.173736</td>\n",
       "      <td>2.173736</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9e745667-0701-434a-8ecb-d917fe2bcf29</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV03 Image 1040010068D32900</td>\n",
       "      <td>2</td>\n",
       "      <td>5.064383</td>\n",
       "      <td>5.064383</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9e508b07-4534-4e04-bb5b-bb0d3734a796</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV03 Image 1040010068D32900</td>\n",
       "      <td>2</td>\n",
       "      <td>4.995412</td>\n",
       "      <td>4.995412</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1cbca6da-0024-47dc-bb3a-06f8727d1cd6</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV03 Image 1040010068D32900</td>\n",
       "      <td>3</td>\n",
       "      <td>1.837958</td>\n",
       "      <td>1.837958</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e7223a4d-68c6-4d32-b140-f871dec62bd3</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV03 Image 1040010068D32900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.816334</td>\n",
       "      <td>0.816334</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0b9ef620-327a-4be2-8b0c-50ec0fa06788</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV02 Image 10300100C00E8900</td>\n",
       "      <td>2</td>\n",
       "      <td>4.812386</td>\n",
       "      <td>4.812386</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e7e42658-360a-4452-8be4-60ea8d1ef0e7</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV03 Image 1040010068D32900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.989220</td>\n",
       "      <td>0.989220</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e18c2562-7f73-4fd2-a361-a6eee01ed71a</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV03 Image 1040010068D32900</td>\n",
       "      <td>2</td>\n",
       "      <td>26.759144</td>\n",
       "      <td>26.759144</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4d13b994-be20-4392-9f0f-68709607e96b</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV03 Image 1040010068D32900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.275426</td>\n",
       "      <td>0.275426</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c9b59851-e4b7-4271-ac99-f4e601f86e85</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV03 Image 1040010068D32900</td>\n",
       "      <td>2</td>\n",
       "      <td>5.644608</td>\n",
       "      <td>5.644608</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>212d5966-2c94-4db7-98e9-4847cfdc4215</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV02 Image 10300100C00E8900</td>\n",
       "      <td>3</td>\n",
       "      <td>2.293858</td>\n",
       "      <td>2.293858</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8bc43765-9e53-4702-ba97-13005b806126</td>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>Maxar WV02 Image 10300100B3A8FB00</td>\n",
       "      <td>2</td>\n",
       "      <td>14.707241</td>\n",
       "      <td>14.707241</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>e41e8d8a-efa3-4626-bbfe-5af48f23b6da</td>\n",
       "      <td>529e1bae-2187-473f-a2a3-17e577720aba</td>\n",
       "      <td>Maxar WV02 Image 10300100DF537E00</td>\n",
       "      <td>1</td>\n",
       "      <td>70.161619</td>\n",
       "      <td>70.161619</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0b35ba48-a92c-48da-83d8-c21ddcdc3c0f</td>\n",
       "      <td>529e1bae-2187-473f-a2a3-17e577720aba</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1.483652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 poly_id  \\\n",
       "0   a91435c7-a179-4c1d-9891-de0fe1741654   \n",
       "1   410696dc-9579-4412-9c7b-55194cb1867c   \n",
       "2   f6871a61-a766-451a-be90-086219616cef   \n",
       "3   9e745667-0701-434a-8ecb-d917fe2bcf29   \n",
       "4   9e508b07-4534-4e04-bb5b-bb0d3734a796   \n",
       "5   1cbca6da-0024-47dc-bb3a-06f8727d1cd6   \n",
       "6   e7223a4d-68c6-4d32-b140-f871dec62bd3   \n",
       "7   0b9ef620-327a-4be2-8b0c-50ec0fa06788   \n",
       "8   e7e42658-360a-4452-8be4-60ea8d1ef0e7   \n",
       "9   e18c2562-7f73-4fd2-a361-a6eee01ed71a   \n",
       "10  4d13b994-be20-4392-9f0f-68709607e96b   \n",
       "11  c9b59851-e4b7-4271-ac99-f4e601f86e85   \n",
       "12  212d5966-2c94-4db7-98e9-4847cfdc4215   \n",
       "13  8bc43765-9e53-4702-ba97-13005b806126   \n",
       "14  e41e8d8a-efa3-4626-bbfe-5af48f23b6da   \n",
       "15  0b35ba48-a92c-48da-83d8-c21ddcdc3c0f   \n",
       "\n",
       "                              project_id                         best_image  \\\n",
       "0   146b6912-62a1-4b58-b027-466dc3295731  Maxar WV02 Image 10300100E93C2A00   \n",
       "1   3a860077-df4c-4e95-8fec-41520c551243  Maxar WV03 Image 1040010068D32900   \n",
       "2   3a860077-df4c-4e95-8fec-41520c551243  Maxar WV03 Image 1040010068D32900   \n",
       "3   3a860077-df4c-4e95-8fec-41520c551243  Maxar WV03 Image 1040010068D32900   \n",
       "4   3a860077-df4c-4e95-8fec-41520c551243  Maxar WV03 Image 1040010068D32900   \n",
       "5   3a860077-df4c-4e95-8fec-41520c551243  Maxar WV03 Image 1040010068D32900   \n",
       "6   3a860077-df4c-4e95-8fec-41520c551243  Maxar WV03 Image 1040010068D32900   \n",
       "7   3a860077-df4c-4e95-8fec-41520c551243  Maxar WV02 Image 10300100C00E8900   \n",
       "8   3a860077-df4c-4e95-8fec-41520c551243  Maxar WV03 Image 1040010068D32900   \n",
       "9   3a860077-df4c-4e95-8fec-41520c551243  Maxar WV03 Image 1040010068D32900   \n",
       "10  3a860077-df4c-4e95-8fec-41520c551243  Maxar WV03 Image 1040010068D32900   \n",
       "11  3a860077-df4c-4e95-8fec-41520c551243  Maxar WV03 Image 1040010068D32900   \n",
       "12  3a860077-df4c-4e95-8fec-41520c551243  Maxar WV02 Image 10300100C00E8900   \n",
       "13  3a860077-df4c-4e95-8fec-41520c551243  Maxar WV02 Image 10300100B3A8FB00   \n",
       "14  529e1bae-2187-473f-a2a3-17e577720aba  Maxar WV02 Image 10300100DF537E00   \n",
       "15  529e1bae-2187-473f-a2a3-17e577720aba                               None   \n",
       "\n",
       "    num_images  poly_area_ha  overlap_area_ha  percent_img_cover  \n",
       "0            1     69.680122        44.213046          63.451447  \n",
       "1            2     11.092460        11.092460         100.000000  \n",
       "2            2      2.173736         2.173736         100.000000  \n",
       "3            2      5.064383         5.064383         100.000000  \n",
       "4            2      4.995412         4.995412         100.000000  \n",
       "5            3      1.837958         1.837958         100.000000  \n",
       "6            2      0.816334         0.816334         100.000000  \n",
       "7            2      4.812386         4.812386         100.000000  \n",
       "8            2      0.989220         0.989220         100.000000  \n",
       "9            2     26.759144        26.759144         100.000000  \n",
       "10           2      0.275426         0.275426         100.000000  \n",
       "11           2      5.644608         5.644608         100.000000  \n",
       "12           3      2.293858         2.293858         100.000000  \n",
       "13           2     14.707241        14.707241         100.000000  \n",
       "14           1     70.161619        70.161619         100.000000  \n",
       "15           0      1.483652         0.000000           0.000000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST COMPUTE POLYGON IMAGE COVERAGE\n",
    "# Initialize storage for results & low-coverage polygons list\n",
    "low_img_coverage_log = []\n",
    "results = []\n",
    "\n",
    "# Iterate through all polygons and compute imagery coverage per polygon\n",
    "for poly_id, project_id in zip(poly_gdf['poly_id'], poly_gdf['project_id']):\n",
    "    result = compute_polygon_image_coverage(poly_id, project_id, poly_gdf, img_gdf_filtered, low_img_coverage_log)\n",
    "    #print(\"Low Image Coverage Log Contents:\", low_img_coverage_log)\n",
    "    results.append(result)\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['poly_id', 'project_id', 'best_image', 'num_images',\n",
    "                                            'poly_area_ha', 'overlap_area_ha', 'percent_img_cover'])\n",
    "\n",
    "# Convert low-coverage log to DataFrame\n",
    "low_coverage_polygons_df = pd.DataFrame(low_img_coverage_log)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Processed {len(results_df)} polygons.\")\n",
    "print(f\"{len(low_coverage_polygons_df)} polygons logged as low imagery coverage.\")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly_id               object\n",
      "project_id            object\n",
      "best_image            object\n",
      "num_images             int64\n",
      "poly_area_ha         float64\n",
      "overlap_area_ha      float64\n",
      "percent_img_cover    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(results_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'poly_id': '0b35ba48-a92c-48da-83d8-c21ddcdc3c0f', 'project_id': '529e1bae-2187-473f-a2a3-17e577720aba', 'best_image': None, 'num_images': 0, 'poly_area_ha': 1.4836519390028373, 'overlap_area_ha': 0, 'percent_img_cover': 0}]\n"
     ]
    }
   ],
   "source": [
    "print(low_img_coverage_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poly_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>best_image</th>\n",
       "      <th>num_images</th>\n",
       "      <th>poly_area_ha</th>\n",
       "      <th>overlap_area_ha</th>\n",
       "      <th>percent_img_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0b35ba48-a92c-48da-83d8-c21ddcdc3c0f</td>\n",
       "      <td>529e1bae-2187-473f-a2a3-17e577720aba</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1.483652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                poly_id                            project_id  \\\n",
       "0  0b35ba48-a92c-48da-83d8-c21ddcdc3c0f  529e1bae-2187-473f-a2a3-17e577720aba   \n",
       "\n",
       "  best_image  num_images  poly_area_ha  overlap_area_ha  percent_img_cover  \n",
       "0       None           0      1.483652                0                  0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_coverage_polygons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       num_images  poly_area_ha  overlap_area_ha  percent_img_cover\n",
      "count   16.000000     16.000000        16.000000          16.000000\n",
      "mean     1.875000     13.924222        12.239802          91.465715\n",
      "std      0.718795     22.882506        19.419146          26.039012\n",
      "min      0.000000      0.275426         0.000000           0.000000\n",
      "25%      2.000000      1.749381         1.625773         100.000000\n",
      "50%      2.000000      4.903899         4.903899         100.000000\n",
      "75%      2.000000     11.996155        11.996155         100.000000\n",
      "max      3.000000     70.161619        70.161619         100.000000\n"
     ]
    }
   ],
   "source": [
    "print(results_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 poly_id  \\\n",
      "15  0b35ba48-a92c-48da-83d8-c21ddcdc3c0f   \n",
      "\n",
      "                              project_id best_image  num_images  poly_area_ha  \\\n",
      "15  529e1bae-2187-473f-a2a3-17e577720aba       None           0      1.483652   \n",
      "\n",
      "    overlap_area_ha  percent_img_cover  \n",
      "15              0.0                0.0  \n"
     ]
    }
   ],
   "source": [
    "low_coverage_cases = results_df[results_df['percent_img_cover'] < 50]\n",
    "print(low_coverage_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(results_df[\"percent_img_cover\"], bins=20, edgecolor=\"black\")\n",
    "plt.xlabel(\"Percent Imagery Coverage\")\n",
    "plt.ylabel(\"Number of Polygons\")\n",
    "plt.title(\"Distribution of Imagery Coverage per Polygon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final outputs!\n"
     ]
    }
   ],
   "source": [
    "## SAVE OUT RESULTS\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "results_df.to_csv(f\"{results_path}polygon_imagery_coverage_{today}.csv\")\n",
    "\n",
    "low_coverage_polygons_df.to_csv(f\"{results_path}low_coverage_polygons_{today}.csv\")\n",
    "print(\"Saved final outputs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 projects being analyzed.\n"
     ]
    }
   ],
   "source": [
    "project_results_df = aggregate_project_image_coverage(results_df, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>num_polygons</th>\n",
       "      <th>num_polygons_with_images</th>\n",
       "      <th>num_polygons_no_images</th>\n",
       "      <th>total_project_area_ha</th>\n",
       "      <th>total_overlap_area_ha</th>\n",
       "      <th>total_percent_area_covered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146b6912-62a1-4b58-b027-466dc3295731</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.680122</td>\n",
       "      <td>44.213046</td>\n",
       "      <td>63.451447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3a860077-df4c-4e95-8fec-41520c551243</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>81.462165</td>\n",
       "      <td>81.462165</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>529e1bae-2187-473f-a2a3-17e577720aba</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.645271</td>\n",
       "      <td>70.161619</td>\n",
       "      <td>97.929170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             project_id  num_polygons  \\\n",
       "0  146b6912-62a1-4b58-b027-466dc3295731             1   \n",
       "1  3a860077-df4c-4e95-8fec-41520c551243            13   \n",
       "2  529e1bae-2187-473f-a2a3-17e577720aba             2   \n",
       "\n",
       "   num_polygons_with_images  num_polygons_no_images  total_project_area_ha  \\\n",
       "0                         1                       0              69.680122   \n",
       "1                        13                       0              81.462165   \n",
       "2                         1                       1              71.645271   \n",
       "\n",
       "   total_overlap_area_ha  total_percent_area_covered  \n",
       "0              44.213046                   63.451447  \n",
       "1              81.462165                  100.000000  \n",
       "2              70.161619                   97.929170  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(project_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_results_df.to_csv(f\"{results_path}project_imagery_coverage_{today}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
