{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Pull PPC Polygons from TerraMatch API\n",
    "\n",
    "This notebook sets up the process to pull PPC polygon geometries and metadata from the TerraMatch API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from tm_api_utils import pull_tm_api_data, patch_tm_api_data\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.append('../src/')\n",
    "import api_utils as api\n",
    "import process_tm_api_results as clean\n",
    "import geospatial_utils_NEW as geo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Set file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming convention\n",
    "run_name = 'ppc_2025_batch2'\n",
    "#run_dir = 'ppc_batch2'\n",
    "\n",
    "# Today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d') # Check computer date before running\n",
    "\n",
    "## Input Files\n",
    "# List of all approved projects on TerraMatch\n",
    "approved_projects_file = '../projects_all_approved_202502211226.csv'\n",
    "\n",
    "# PPC Batch 2 Project List\n",
    "batch2_projects = \"../data/ppc/ppc_2025_batch2_project_list.csv\"\n",
    "\n",
    "# PPC Prospective Tree Count (Group 1) Projects\n",
    "#tree_count_group1_file = '/home/darby/github_repos/tf-biophysical-monitoring/data/ppc/ppc_tree_count_projects_group1_20250509.csv'\n",
    "#tree_count_file = '~/github_repos/tf-biophysical-monitoring/data/ppc/ppc_2025_potential_tree_count_projects_2025-07-16.csv'\n",
    "\n",
    "## Output Files\n",
    "# A JSON file that stores the results of the TM API pull; we'll read it back in to clean the results (outfile, infile)\n",
    "tm_api_pull_results_file = f'/home/darby/github_repos/tf-biophysical-monitoring/data/ppc/tm_api_response_prod_{run_name}_{today}.json'\n",
    "\n",
    "# The cleaned polygon features csv\n",
    "polygon_features_file = f'/home/darby/github_repos/tf-biophysical-monitoring/data/ppc/tm_api_{run_name}_{today}.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all approved projects on TerraMatch\n",
    "approved_projects_df = pd.read_csv(approved_projects_file)\n",
    "\n",
    "# PPC Prospective Tree Count (Group 1) Projects\n",
    "#tree_count_df = pd.read_csv(tree_count_group1_file)\n",
    "#tree_count_df = pd.read_csv(tree_count_file)\n",
    "\n",
    "# PPC 2025 Batch 2 Projects\n",
    "batch2_projects_df = pd.read_csv(batch2_projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Set up token and API URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up token access\n",
    "auth_path = '../secrets.yaml'\n",
    "with open(auth_path) as auth_file:\n",
    "    auth = yaml.safe_load(auth_file)\n",
    "headers = {\n",
    "    'Authorization': f\"Bearer {auth['access_token']}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TerraMatch API URLs\n",
    "staging_url = \"https://api-staging.terramatch.org/research/v3/sitePolygons?\" # Use for testing queries\n",
    "prod_url = \"https://api.terramatch.org/research/v3/sitePolygons?\" # Use to pull data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Create list of projects to pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Pull Projects from group list (Batch 1, prospective tree count group 1, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the unique project_ids from the Batch 1 projects\n",
    "batch2_proj_ids = list(batch2_projects_df['project_id'].unique())\n",
    "batch2_proj_ids\n",
    "# batch2_proj_ids = ['02b3119e-9505-4dba-b58d-f2a967b71ef9', '5e8a3c5e-7a28-4ff4-be07-f950361f56b2', '5bb542b2-0efb-4b52-841f-2b5898f533b8',\n",
    "#                     'ad149677-7ee0-479c-8d23-aa8c3bf58532', '7e7d390b-1894-4a1b-acc2-c531f213c1ca', 'd2c2a1fe-c5e8-435a-b865-00dce7a9809f',\n",
    "#                     'c8ef8d8e-a75a-46f4-88d4-8057ed5a50f8', 'e4108d7a-58d8-4604-8dd8-2f95c9c181d5']\n",
    "\n",
    "# Potential tree count projects list from Asana: https://app.asana.com/1/25496124013636/project/1208493878648584/task/1210412708479452?focus=true\n",
    "#tree_count_proj_ids = list(tree_count_df['project_id'].unique())\n",
    "#tree_count_proj_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### OR Pull projects from list of all approved polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the list of all approved projects by cohort ('ppc'), project_id (the Batch 1 list), \n",
    "ppc = approved_projects_df[approved_projects_df['cohort'] == 'ppc']\n",
    "\n",
    "# Filter to just the batch 1 projects list\n",
    "batch2 = ppc[ppc['project_id'].isin(batch2_proj_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Pull polygons from TM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = api.pull_wrapper(prod_url, headers, batch2_proj_ids, outfile=tm_api_pull_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(f\"df has {df.project_id.nunique()} unique projects\")\n",
    "print(f\"df has {df.poly_id.nunique()} unique polygons\")\n",
    "df['project_id'].value_counts()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA values\n",
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Clean attributes and save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved JSON file\n",
    "with open(tm_api_pull_results_file, 'r') as file:\n",
    "    project_results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the csv and transform it into a dataframe\n",
    "## Identifies and converts invalid plantstart and plantend dates to NaT\n",
    "## Saves one copy of the polygon features csv to the terrafund-portfolio-analysis repo and one to the maxar-tools repo\n",
    "clean_api = clean.process_tm_api_results(project_results,\n",
    "                                         '2020-01-01',\n",
    "                                         outfile1 = polygon_features_file,\n",
    "                                         outfile2 = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Check Processed CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_df = pd.read_csv('/home/darby/github_repos/tf-biophysical-monitoring/data/ppc/batch2_2025/tm_api_ppc_2025_batch2_2025-08-22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tc_df))\n",
    "print(f\"df has {tc_df.project_id.nunique()} unique projects\")\n",
    "print(f\"df has {tc_df.poly_id.nunique()} unique polygons\")\n",
    "tc_df['project_id'].value_counts()\n",
    "tc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Filter PPC polygons by desired plantstart years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_df_filt = clean.filter_by_years_of_interest(tc_df, batch2_projects_df)\n",
    "print(tc_df_filt.shape)\n",
    "tc_df_filt.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered csv (overwrite the previous csv unless otherwise specified)\n",
    "tc_df_filt.to_csv(polygon_features_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_df = pd.read_csv(polygon_features_file)\n",
    "print(tc_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA values\n",
    "tc_df.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
