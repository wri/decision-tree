{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d9ad79",
   "metadata": {},
   "source": [
    "# Analyze Maxar Image Availability\n",
    "\n",
    "Takes in a CSVs of:\n",
    "- All polygon features\n",
    "- All Maxar images available for those polygons\n",
    "- Filtered mage availability per polygon\n",
    "- Filtered image availability per project (aggregated)\n",
    "- Low coverage polygons\n",
    "\n",
    "Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffdc3c7",
   "metadata": {},
   "source": [
    "Outline:\n",
    "\n",
    "Step 1: Load already computed CSVs for:\n",
    " - poly_img_avail_base_df\n",
    " - poly_img_avail_ev_df\n",
    " - project_img_avail_base_df\n",
    " - project_img_avail_ev_df\n",
    " - poly_gdf\n",
    " - maxar_gdf\n",
    "\n",
    "Step 2: Merge plantstart years (from poly_gdf) into polygon-level image availability\n",
    "\n",
    "Step 3: Calculate planting year distributions (by polygon)\n",
    "\n",
    "Step 4: Assemble baseline & EV coverage from project-level files\n",
    "\n",
    "Step 5: Calculate % area covered by baseline and by EV imagery\n",
    "\n",
    "Step 6: Calculate % area with coverage at both points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe30db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import image_coverage as img_cover\n",
    "import analyze_img_coverage as analyze\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79379d32",
   "metadata": {},
   "source": [
    "## Set file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c2432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input file paths\n",
    "# Polygon metadata & geometries from TM API\n",
    "feats = '../data/tf_cohort1/tm_api_cohort1_2025-04-02.csv' \n",
    "\n",
    "# Metadata for Maxar images corresponding to polygons\n",
    "maxar_md = '../data/tf_cohort1/imagery_availability/comb_img_availability_cohort1_2025-04-02.csv' \n",
    "\n",
    "# List of approved projects (with country codes)\n",
    "approved_projects = '../projects_all_approved_202502211226.csv'\n",
    "\n",
    "# Image availability\n",
    "# Baseline\n",
    "poly_img_avail_base = '../data/tf_cohort1/results/baseline/polygon_imagery_coverage_cohort1_2025-04-02.csv'\n",
    "low_cov_poly_base = '../data/tf_cohort1/results/baseline/low_coverage_polygons_cohort1_2025-04-02.csv'\n",
    "proj_img_avail_base = '../data/tf_cohort1/results/baseline/project_imagery_coverage_cohort1_2025-04-02.csv'\n",
    "\n",
    "# Early Verification\n",
    "poly_img_avail_ev = '../data/tf_cohort1/results/year_2/polygon_imagery_coverage_cohort1_2025-04-02.csv'\n",
    "low_cov_poly_ev = '../data/tf_cohort1/results/year_2/low_coverage_polygons_cohort1_2025-04-02.csv'\n",
    "proj_img_avail_ev = '../data/tf_cohort1/results/year_2/project_imagery_coverage_cohort1_2025-04-02.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa9500",
   "metadata": {},
   "source": [
    "## Read in files|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a753aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polygon feature data\n",
    "poly_df = pd.read_csv(feats)\n",
    "\n",
    "# Maxar data\n",
    "maxar_df = pd.read_csv(maxar_md)\n",
    "\n",
    "# Image availability\n",
    "# Baseline\n",
    "poly_img_avail_base_df = pd.read_csv(poly_img_avail_base)\n",
    "low_cov_poly_base_df = pd.read_csv(low_cov_poly_base)\n",
    "proj_img_avail_base_df = pd.read_csv(proj_img_avail_base)\n",
    "\n",
    "# Early Verification\n",
    "poly_img_avail_ev_df = pd.read_csv(poly_img_avail_ev)\n",
    "low_cov_poly_ev_df = pd.read_csv(low_cov_poly_ev)\n",
    "proj_img_avail_ev_df = pd.read_csv(proj_img_avail_ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a76294b",
   "metadata": {},
   "source": [
    "## Preprocess polygon and maxar image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8192f221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing polygon data...\n",
      "Cleaning geometries...\n",
      "\n",
      "ðŸ§¾ Geometry Cleaning Summary:\n",
      "  âž¤ Total geometries processed: 13537\n",
      "  âž¤ Invalid geometries:         0\n",
      "  âž¤ Repaired with buffer(0):    0\n",
      "  âž¤ Dropped:                    0\n",
      "  âœ… Final valid polygons:       13537\n",
      "\n",
      "Processing Maxar image data...\n",
      "There are 175641 images for 12168 polygons in 78 projects in this dataset.\n"
     ]
    }
   ],
   "source": [
    "poly_gdf = img_cover.preprocess_polygons(poly_df, debug=True)\n",
    "maxar_gdf = img_cover.preprocess_images(maxar_df, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f5979f",
   "metadata": {},
   "source": [
    "## Merge 'plantstart' and poly_geom into image availability data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d04a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge plantstart and poly_geom into baseline and EV image availability\n",
    "poly_img_avail_base_df = poly_img_avail_base_df.merge(poly_gdf[['poly_id', 'plantstart', 'poly_geom']], on='poly_id', how='left')\n",
    "poly_img_avail_ev_df = poly_img_avail_ev_df.merge(poly_gdf[['poly_id', 'plantstart', 'poly_geom']], on='poly_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5903065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poly_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>best_image</th>\n",
       "      <th>num_images</th>\n",
       "      <th>poly_area_ha</th>\n",
       "      <th>overlap_area_ha</th>\n",
       "      <th>percent_img_cover</th>\n",
       "      <th>plantstart</th>\n",
       "      <th>poly_geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a40e322b-42ff-4008-8407-e611b170a39c</td>\n",
       "      <td>389aad5b-6577-4cea-bf9f-446dcfd94966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>POLYGON ((31.39719 1.51653, 31.3972 1.51652, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9dcccf42-cd63-471b-a251-abd1009fb819</td>\n",
       "      <td>389aad5b-6577-4cea-bf9f-446dcfd94966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>POLYGON ((31.39611 1.51079, 31.39611 1.51075, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                poly_id                            project_id  \\\n",
       "0  a40e322b-42ff-4008-8407-e611b170a39c  389aad5b-6577-4cea-bf9f-446dcfd94966   \n",
       "1  9dcccf42-cd63-471b-a251-abd1009fb819  389aad5b-6577-4cea-bf9f-446dcfd94966   \n",
       "\n",
       "  best_image  num_images  poly_area_ha  overlap_area_ha  percent_img_cover  \\\n",
       "0        NaN           0      0.231599              0.0                0.0   \n",
       "1        NaN           0      0.467551              0.0                0.0   \n",
       "\n",
       "  plantstart                                          poly_geom  \n",
       "0 2022-01-08  POLYGON ((31.39719 1.51653, 31.3972 1.51652, 3...  \n",
       "1 2022-01-08  POLYGON ((31.39611 1.51079, 31.39611 1.51075, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_img_avail_base_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d688de0",
   "metadata": {},
   "source": [
    "## Calculate planting year stats by project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ed220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from plantstart\n",
    "poly_img_avail_base_df['plant_year'] = poly_img_avail_base_df['plantstart'].dt.year\n",
    "\n",
    "# Group by project and calculate planting year distinctions\n",
    "planting_stats = poly_img_avail_base_df.groupby('project_id').agg(\n",
    "    num_poly=('poly_id', 'count'),\n",
    "    pct_poly_plant_2022=('plant_year', lambda x: (x == 2022).sum() / len(x) * 100),\n",
    "    pct_poly_plant_2023=('plant_year', lambda x: (x == 2023).sum() / len(x) * 100),\n",
    "    pct_poly_plant_2024=('plant_year', lambda x: (x == 2024).sum() / len(x) * 100),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac77684",
   "metadata": {},
   "source": [
    "## Calculate % polygons with imagery at baseline & early verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aab86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count % of polygons with at least one baseline image\n",
    "poly_img_avail_base_df['has_base_img'] = poly_img_avail_base_df['num_images'] > 0\n",
    "base_img_stats = poly_img_avail_base_df.groupby('project_id')['has_base_img'].mean().reset_index()\n",
    "base_img_stats = base_img_stats.rename(columns={'has_base_img': 'pct_poly_wi_base_img'})\n",
    "base_img_stats['pct_poly_wi_base_img'] *= 100\n",
    "\n",
    "# Count # of polygons with at least one early verification image\n",
    "poly_img_avail_ev_df['has_ev_img'] = poly_img_avail_ev_df['num_images'] > 0\n",
    "ev_img_stats = poly_img_avail_ev_df.groupby('project_id')['has_ev_img'].mean().reset_index()\n",
    "ev_img_stats = ev_img_stats.rename(columns={'has_ev_img': 'pct_poly_wi_ev_img'})\n",
    "ev_img_stats['pct_poly_wi_ev_img'] *= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde5840",
   "metadata": {},
   "source": [
    "## Calculate % of polygons with high image coverage (> 70%) at both time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc23b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only needed columns\n",
    "base_cov = poly_img_avail_base_df[['poly_id', 'project_id', 'percent_img_cover']].copy()\n",
    "ev_cov = poly_img_avail_ev_df[['poly_id', 'percent_img_cover']].copy()\n",
    "\n",
    "# Rename for clarity before merge\n",
    "base_cov = base_cov.rename(columns={'percent_img_cover': 'base_pct_img_cover'})\n",
    "ev_cov = ev_cov.rename(columns={'percent_img_cover': 'ev_pct_img_cover'})\n",
    "\n",
    "# Merge coverage values by poly_id\n",
    "joined_cov = base_cov.merge(ev_cov, on='poly_id', how='inner')\n",
    "\n",
    "# Define a coverage threshold for \"high coverage\"\n",
    "cover_thresh = 70\n",
    "\n",
    "# Check if both timepoints have > 70% coverage\n",
    "joined_cov['high_cov_both'] = (\n",
    "    (joined_cov['base_pct_img_cover'] >= cover_thresh) &\n",
    "    (joined_cov['ev_pct_img_cover'] >= cover_thresh)\n",
    ")\n",
    "\n",
    "# Group by project and compute % of polygons with high coverage at both\n",
    "high_cov_stats = joined_cov.groupby('project_id')['high_cov_both'].mean().reset_index()\n",
    "high_cov_stats['pct_poly_wi_high_cov_both'] = high_cov_stats['high_cov_both'] * 100\n",
    "high_cov_stats = high_cov_stats.drop(columns='high_cov_both')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6553a3",
   "metadata": {},
   "source": [
    "## Assemble summary table at project level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b753ad7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>num_poly</th>\n",
       "      <th>pct_poly_plant_2022</th>\n",
       "      <th>pct_poly_plant_2023</th>\n",
       "      <th>pct_poly_plant_2024</th>\n",
       "      <th>pct_poly_wi_base_img</th>\n",
       "      <th>pct_poly_wi_ev_img</th>\n",
       "      <th>pct_poly_wi_high_cov_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33274073-8a4e-4eca-8b97-0e8da3833105</td>\n",
       "      <td>8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              project_id  num_poly  pct_poly_plant_2022  \\\n",
       "13  33274073-8a4e-4eca-8b97-0e8da3833105         8                100.0   \n",
       "\n",
       "    pct_poly_plant_2023  pct_poly_plant_2024  pct_poly_wi_base_img  \\\n",
       "13                  0.0                  0.0                 100.0   \n",
       "\n",
       "    pct_poly_wi_ev_img  pct_poly_wi_high_cov_both  \n",
       "13               100.0                      100.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start from planting_stats (project_id, number of polygons, and % that started planting each year)\n",
    "project_summary_df = planting_stats.copy()\n",
    "\n",
    "# Merge in baseline image availability\n",
    "project_summary_df = project_summary_df.merge(base_img_stats, on='project_id', how='left')\n",
    "\n",
    "# Merge in early verification image availability\n",
    "project_summary_df = project_summary_df.merge(ev_img_stats, on='project_id', how='left')\n",
    "\n",
    "# Merge in % polygons with high coverage at both time points\n",
    "project_summary_df = project_summary_df.merge(high_cov_stats, on='project_id', how='left')\n",
    "\n",
    "project_summary_df = project_summary_df.sort_values(by='pct_poly_wi_high_cov_both', ascending=False)\n",
    "project_summary_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dac48",
   "metadata": {},
   "source": [
    "## Calculate % of project area with imagery at baseline and early verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9762e619",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45af0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img_id(title):\n",
    "    \"\"\"\n",
    "    Extracts the Maxar image ID from the Maxar image title \n",
    "    \"\"\"\n",
    "    if isinstance(title, str) and title.startswith(\"Maxar\"):\n",
    "        return title.split()[-1]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b957b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "941d17ed",
   "metadata": {},
   "source": [
    "### Create a dataframe with best image id and geometry for all polygons for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b2f9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an 'img_id' column to the dataframes of polygon-level best image availability at baseline & EV\n",
    "poly_img_avail_base_df['img_id_base'] = poly_img_avail_base_df['best_image'].apply(extract_img_id)\n",
    "poly_img_avail_ev_df['img_id_ev'] = poly_img_avail_ev_df['best_image'].apply(extract_img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55ea56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with each unique img_id (and it associated geometry) from maxar_gdf\n",
    "img_geom_lookup = maxar_gdf[['img_id', 'img_geom']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bc805ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the image's footprint geometry (img_geom) to each relevent row in poly_img_avail_base/ev_df\n",
    "\n",
    "# Baseline\n",
    "poly_img_avail_base_df = poly_img_avail_base_df.merge(\n",
    "    img_geom_lookup.rename(columns={'img_id': 'img_id_base', 'img_geom': 'img_geom_base'}),\n",
    "    on='img_id_base', how='left'\n",
    ")\n",
    "\n",
    "# Early verification\n",
    "poly_img_avail_ev_df = poly_img_avail_ev_df.merge(\n",
    "    img_geom_lookup.rename(columns={'img_id': 'img_id_ev', 'img_geom': 'img_geom_ev'}),\n",
    "    on='img_id_ev', how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ffc6510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of poly_double_cov_df before filtering: 13537\n",
      "Length of poly_double_cov_df after filtering: 3753\n"
     ]
    }
   ],
   "source": [
    "## Build a dataframe with all relevent info for the best image at baseline & EV for each polygon ##\n",
    "\n",
    "# Step 1: Select relevent columns from baseline dataframe and rename\n",
    "base_cols = poly_img_avail_base_df[[\n",
    "    'poly_id', 'project_id', 'plantstart', 'poly_geom',\n",
    "    'best_image', 'img_id_base', 'percent_img_cover', 'img_geom_base'\n",
    "]].rename(columns={\n",
    "    'best_image': 'best_image_base',\n",
    "    'percent_img_cover': 'percent_img_cover_base',\n",
    "})\n",
    "\n",
    "# Step 2: Select relevent columns from early verification dataframe and rename\n",
    "ev_cols = poly_img_avail_ev_df[[\n",
    "    'poly_id', 'best_image', 'img_id_ev', 'percent_img_cover', 'img_geom_ev'\n",
    "]].rename(columns={\n",
    "    'best_image': 'best_image_ev',\n",
    "    'percent_img_cover': 'percent_img_cover_ev',\n",
    "})\n",
    "\n",
    "# Step 3: Merge baseline and EV info on poly_id (inner)\n",
    "#  This creates a DF with ONLY polygons with a best image at both baseline & EV\n",
    "poly_double_cov_df = base_cols.merge(ev_cols, on='poly_id', how='inner')\n",
    "\n",
    "print(f\"Length of poly_double_cov_df before filtering: {len(poly_double_cov_df)}\")\n",
    "\n",
    "# Step 4: Filter to only include polygons with a best image at both baseline & EV\n",
    "poly_double_cov_df = poly_double_cov_df.dropna(subset=['best_image_base', 'best_image_ev'])\n",
    "print(f\"Length of poly_double_cov_df after filtering: {len(poly_double_cov_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f44ae241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #53 - very small overlap\n",
    "# #117\n",
    "# test_row = poly_double_cov_df.iloc[117]\n",
    "# print(\"Test row:\")\n",
    "# print(test_row)\n",
    "# print()\n",
    "\n",
    "# # Extract geometries\n",
    "# poly_geom = test_row['poly_geom']\n",
    "# img_geom_base = test_row['img_geom_base']\n",
    "# img_geom_ev = test_row['img_geom_ev']\n",
    "\n",
    "# # Get UTM CRS from polygon centroid\n",
    "# centroid = poly_geom.centroid\n",
    "# utm_crs = img_cover.get_utm_crs(centroid.x, centroid.y)\n",
    "# print(f\"Using UTM CRS: {utm_crs}\")\n",
    "\n",
    "# # Reproject all geometries to UTM\n",
    "# poly_proj = gpd.GeoSeries([poly_geom], crs=\"EPSG:4326\").to_crs(utm_crs).iloc[0]\n",
    "# base_proj = gpd.GeoSeries([img_geom_base], crs=\"EPSG:4326\").to_crs(utm_crs).iloc[0]\n",
    "# ev_proj = gpd.GeoSeries([img_geom_ev], crs=\"EPSG:4326\").to_crs(utm_crs).iloc[0]\n",
    "\n",
    "# # Calculate polygon area (ha)\n",
    "# poly_area_ha = poly_proj.area / 10_000\n",
    "# print(f\"Polygon area: {poly_area_ha:.2f} ha\")\n",
    "\n",
    "# # Get overlaps\n",
    "# overlap_base = poly_proj.intersection(base_proj)\n",
    "# overlap_ev = poly_proj.intersection(ev_proj)\n",
    "\n",
    "# # Get intersection of overlaps\n",
    "# overlap_both = overlap_base.intersection(overlap_ev)\n",
    "\n",
    "# # Compute shared coverage area (ha)\n",
    "# overlap_area_ha = overlap_both.area / 10_000\n",
    "# percent_overlap = (overlap_area_ha / poly_area_ha) * 100\n",
    "\n",
    "# # Print results\n",
    "# print()\n",
    "# print(f\"Overlap with both images: {overlap_area_ha:.6f} ha\")\n",
    "# print(f\"Percent polygon area with shared image coverage: {percent_overlap:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7c11b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shared_image_overlap(row, debug=False):\n",
    "    \"\"\"\n",
    "    Given a row with polygon and baseline/EV image footprints, compute shared area of image coverage\n",
    "    (in hectares and as a % of the polygon's area)\n",
    "    \"\"\"\n",
    "    # Extract geometries\n",
    "    poly_geom = row['poly_geom']\n",
    "    base_img = row['img_geom_base']\n",
    "    ev_geom = row['img_geom_ev']\n",
    "\n",
    "    # Use centroid to determine UTM zone\n",
    "    centroid = poly_geom.centroid\n",
    "    utm_crs = img_cover.get_utm_crs(centroid.x, centroid.y)\n",
    "\n",
    "    # Reproject all geometries to UTM\n",
    "    poly_proj = gpd.GeoSeries([poly_geom], crs=\"EPSG:4326\").to_crs(utm_crs).iloc[0]\n",
    "    base_proj = gpd.GeoSeries([img_geom_base], crs=\"EPSG:4326\").to_crs(utm_crs).iloc[0]\n",
    "    ev_proj = gpd.GeoSeries([img_geom_ev], crs=\"EPSG:4326\").to_crs(utm_crs).iloc[0]\n",
    "\n",
    "    # Compute area of polygon\n",
    "    poly_area_ha = poly_proj.area / 10_000\n",
    "\n",
    "    # Calculate overlap between polygon and imagery at baseline & EV\n",
    "    overlap_base = poly_proj.intersection(base_proj)\n",
    "    overlap_ev = poly_proj.intersection(ev_proj)\n",
    "\n",
    "    # Get intersection of overlaps\n",
    "    shared_overlap = overlap_base.intersection(overlap_ev)\n",
    "\n",
    "    # Calculate area of shared overlap & % of polygon area\n",
    "    shared_overlap_area_ha = shared_overlap.area / 10_000\n",
    "    shared_pct_cover = (shared_overlap_area_ha / poly_area_ha) * 100 if poly_area_ha > 0 else 0\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Polygon area (ha): {poly_area_ha:.2f}\")\n",
    "        print(f\"Shared overlap area (ha): {shared_overlap_area_ha:.4f}\")\n",
    "        print(f\"Shared coverage (%): {shared_pct_cover:.2f}\")\n",
    "\n",
    "    return pd.Series({\n",
    "        'poly_area_ha_actual': poly_area_ha,\n",
    "        'shared_overlap_ha': shared_overlap_area_ha,\n",
    "        'shared_pct_img_cover': shared_pct_cover\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24ecf6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poly_id                                74523827-22f2-48a7-9f87-f190dcab8003\n",
       "project_id                             943bb150-f1b7-4ad2-bb9e-60a559df2ebd\n",
       "plantstart                                              2023-06-05 00:00:00\n",
       "poly_geom                 POLYGON ((-1.735648250031435 5.119492900932012...\n",
       "best_image_base                           Maxar WV02 Image 10300100D4549C00\n",
       "img_id_base                                                10300100D4549C00\n",
       "percent_img_cover_base                                                100.0\n",
       "img_geom_base             POLYGON ((-1.859111 6.014522, -1.85881 5.98260...\n",
       "best_image_ev                             Maxar WV02 Image 103001010F0DA300\n",
       "img_id_ev                                                  103001010F0DA300\n",
       "percent_img_cover_ev                                                  100.0\n",
       "img_geom_ev               POLYGON ((-1.778579 4.962744, -1.604997 4.9798...\n",
       "Name: 930, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_double_cov_df.iloc[117]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
