{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Polygons from TerraMatch API\n",
    "\n",
    "This notebook sets up the process to pull polygon geometries and metadata from the TerraMatch API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from tm_api_utils import pull_tm_api_data, patch_tm_api_data\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.append('../src/')\n",
    "import api_utils as api\n",
    "import process_tm_api_results as clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming convention\n",
    "run_name = 'cohort2'\n",
    "run_dir = 'tf_cohort2'\n",
    "\n",
    "# Today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d') # Check computer date before running\n",
    "\n",
    "# Files\n",
    "approved_projects_file = '../projects_all_approved_202502211226.csv' # List of approved projects (infile)\n",
    "tm_api_pull_results_file = f'../data/{run_dir}/tm_api_response_prod_{run_name}_{today}.json' # Save a JSON file that stores the results of the TM API pull; read it back in to clean the results (outfile, infile)\n",
    "polygon_features_file = f'../data/{run_dir}/tm_api_{run_name}_{today}.csv' # Save the cleaned polygon features csv in the terrafund-portfolio-analyses repo (outfile)\n",
    "polygon_features_maxar_file = f'/home/darby/github_repos/maxar-tools/data/{run_dir}/polygon_data/tm_api_{run_name}_{today}.csv' # Save the cleaned polygon features csv in the maxar-tools repo (outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up token and API URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up token access\n",
    "auth_path = '../secrets.yaml'\n",
    "with open(auth_path) as auth_file:\n",
    "    auth = yaml.safe_load(auth_file)\n",
    "headers = {\n",
    "    'Authorization': f\"Bearer {auth['access_token']}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TerraMatch API URLs\n",
    "staging_url = \"https://api-staging.terramatch.org/research/v3/sitePolygons?\" # Use for testing queries\n",
    "prod_url = \"https://api.terramatch.org/research/v3/sitePolygons?\" # Use to pull data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lists of projects to pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in list of approved projects (2025-02-21)\n",
    "full = pd.read_csv(approved_projects_file)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of projects by Cohort (and split cohort 1 into projects within the TF landscapes and outside of the TF landscapes)\n",
    "cohort1 = full[full['cohort'] == 'terrafund']\n",
    "cohort1_landscapes = cohort1[cohort1['country'].isin(['BI', 'CD', 'RW', 'KE', 'GH'])]\n",
    "cohort1_non_landscapes = cohort1[~cohort1['country'].isin(['BI', 'CD', 'RW', 'KE', 'GH'])]\n",
    "cohort2 = full[full['cohort'] == 'terrafund-landscapes']\n",
    "\n",
    "ppc = full[full['cohort'] == 'ppc']\n",
    "ppc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of project ids to query\n",
    "ids = list(set(cohort2.project_id))\n",
    "len(ids)\n",
    "\n",
    "# Create a short list of ids for testing \n",
    "ids = ids[2:4]\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull polygons from TM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = api.pull_wrapper(prod_url, headers, ids, outfile=tm_api_pull_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(f\"df has {df.project_id.nunique()} unique projects\")\n",
    "print(f\"df has {df.poly_id.nunique()} unique polygons\")\n",
    "df['project_id'].value_counts()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved JSON file\n",
    "with open(tm_api_pull_results_file, 'r') as file:\n",
    "    project_results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the csv and transform it into a dataframe\n",
    "## Identifies and converts invalid plantstart and plantend dates to NaT\n",
    "## Saves one copy of the polygon features csv to the terrafund-portfolio-analysis repo and one to the maxar-tools repo\n",
    "clean_api = clean.process_tm_api_results(project_results,\n",
    "                                         outfile1 = polygon_features_file,\n",
    "                                         outfile2 = polygon_features_maxar_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
